{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AssignmentEVA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILUxchR5qGar",
        "outputId": "ca17a33b-338d-41ef-dcf1-c14549d4a5fe"
      },
      "source": [
        "#Do all Installations\n",
        "!pip install torch\n",
        "!pip install torchsummary"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YT6LGBSpXF7"
      },
      "source": [
        "#Do all Imports\n",
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgdeIxgYqElW"
      },
      "source": [
        "#Do all Downloads\n",
        "mnist = datasets.MNIST(root = \"./data\", train = True, download = True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]))"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogudg9scpbZ8",
        "outputId": "bfa6db3c-8093-406f-a979-6050d0fad2fb"
      },
      "source": [
        "#Create combined dataset\n",
        "import torch.nn.functional as F\n",
        "Combined_Dataset = []\n",
        "for sample_data in iter(mnist):\n",
        "  sample_image, sample_label = sample_data\n",
        "  first_input = sample_image\n",
        "  first_label = sample_label\n",
        "  for i in range(10):\n",
        "    second_label = first_label + i\n",
        "    second_input = i\n",
        "    first_label = torch.tensor(first_label)\n",
        "    second_label_onehot = torch.tensor(second_label)\n",
        "    second_label_onehot = F.one_hot(second_label_onehot, num_classes=19).float()\n",
        "    second_input_onehot = torch.tensor(second_input)\n",
        "    second_input_onehot = F.one_hot(second_input_onehot, num_classes=10)\n",
        "    first_label_onehot = F.one_hot(first_label, num_classes=10)\n",
        "    combined_sample = (first_input,second_input_onehot,first_label_onehot,second_label_onehot)\n",
        "    Combined_Dataset.append(combined_sample)\n",
        "\n",
        "print(\"Dataset size = \",len(Combined_Dataset))"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size =  600000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCtL1eiRquFE"
      },
      "source": [
        "#Create class and iterator\n",
        "class MnistNumberCombinedDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = Combined_Dataset\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "ComData = MnistNumberCombinedDataset()"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgwgSsBDr2TJ"
      },
      "source": [
        "#Create Network class\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # input size = 28 | output size = 24 | numb_channels = 10\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5) \n",
        "    \n",
        "    # input size = 24 | output size = 12 | numb_channels = 10\n",
        "    self.maxpool1 = nn.MaxPool2d(2,2)\n",
        "    \n",
        "    # input size = 12 | output size = 8 | numb_channels = 16\n",
        "    self.conv2 = nn.Conv2d(in_channels=10, out_channels=16, kernel_size=3)\n",
        "\n",
        "    self.conv2drop = nn.Dropout2d()\n",
        "\n",
        "    # input size = 8 | output size = 4 | numb_channels = 16\n",
        "    self.maxpool2 = nn.MaxPool2d(2,2)\n",
        "\n",
        "    \n",
        "    self.fc1 = nn.Linear(in_features = 400,out_features = 50)\n",
        "\n",
        "    self.out1  = nn.Linear(in_features = 50,out_features = 10)\n",
        "\n",
        "    # input size = 10 + 10 | output size = 50\n",
        "    self.fc2 = nn.Linear(in_features=20, out_features=50)\n",
        "\n",
        "    # input size = 50 | output size = 70\n",
        "    self.fc3 = nn.Linear(in_features=50, out_features=70)\n",
        "\n",
        "    # input size = 70 | output size = 19\n",
        "    self.out2 = nn.Linear(in_features=70, out_features=19)\n",
        "    \n",
        "\n",
        "  \n",
        "  def forward(self, image, data):\n",
        "    #print(\"Input Image size = \", image.shape)\n",
        "    x = F.relu(self.maxpool1(self.conv1(image)))\n",
        "    #print(\"After 1st conv size and maxpool1 = \", x.shape)\n",
        "\n",
        "    x = F.relu(self.maxpool2(self.conv2drop(self.conv2(x))))\n",
        "    #print(\"After 2nd conv and Maxpool2 size = \", x.shape)\n",
        "\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    #print(type(x))\n",
        "    #print(\"After reshape size = \",x.shape)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    #print(\"After fc1 size = \",x.shape)\n",
        "\n",
        "    x = F.relu(self.out1(x))\n",
        "    #print(\"After second fc(out1), out =\", x.shape)\n",
        "\n",
        "    self.out1_pred = F.log_softmax(x)\n",
        "\n",
        "    #print(\"Input data size = \", data.shape)\n",
        "    concat = torch.cat((self.out1_pred, data),dim=1)\n",
        "    #print(\"After Concat size = \", concat.shape)\n",
        "\n",
        "    concat = concat.reshape(concat.shape[0],-1)\n",
        "    #print(\"After reshape concat size = \",concat.shape)\n",
        "\n",
        "    x = F.relu(self.fc2(concat))\n",
        "    #print(\"After 2nd FC  size = \", x.shape)\n",
        "    \n",
        "    x = F.relu(self.fc3(x))\n",
        "    #print(\"After 3rd FC  size = \", x.shape)\n",
        "    \n",
        "    self.out_pred2 = F.relu(self.out2(x))\n",
        "    #print(\"After out2 FC, 2nd Output size = \", self.out_pred2.shape)\n",
        "\n",
        "    return (self.out1_pred, self.out_pred2)"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FPIdMIK1qe0",
        "outputId": "e97a9b5e-4b3d-47b0-caa3-e9bd4bda2ebb"
      },
      "source": [
        "#initialize Network object\n",
        "network = Network()\n",
        "\n",
        "for name, param in network.named_parameters():\n",
        "  print(name, '\\t\\t', param.shape)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight \t\t torch.Size([10, 1, 5, 5])\n",
            "conv1.bias \t\t torch.Size([10])\n",
            "conv2.weight \t\t torch.Size([16, 10, 3, 3])\n",
            "conv2.bias \t\t torch.Size([16])\n",
            "fc1.weight \t\t torch.Size([50, 400])\n",
            "fc1.bias \t\t torch.Size([50])\n",
            "out1.weight \t\t torch.Size([10, 50])\n",
            "out1.bias \t\t torch.Size([10])\n",
            "fc2.weight \t\t torch.Size([50, 20])\n",
            "fc2.bias \t\t torch.Size([50])\n",
            "fc3.weight \t\t torch.Size([70, 50])\n",
            "fc3.bias \t\t torch.Size([70])\n",
            "out2.weight \t\t torch.Size([19, 70])\n",
            "out2.bias \t\t torch.Size([19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoBPpp4h4Ida"
      },
      "source": [
        "def combined_loss_function(out1, labels1, out2, labels2):\n",
        "  #out1_argmax = torch.tensor(out1.argmax(dim = 1)).float()\n",
        "  #print(out1_argmax)\n",
        "  #print(out1_argmax.shape)\n",
        "  labels1_argmax = torch.tensor(labels1.argmax(dim=1)).long()\n",
        "  crossentropyloss = nn.CrossEntropyLoss()\n",
        "  loss1 = crossentropyloss(out1, labels1_argmax) #Cross entropy for image\n",
        "  mse_loss = nn.MSELoss() #MSE for sum prediction\n",
        "  loss2 = mse_loss(out2, labels2)\n",
        "  #print(loss1)\n",
        "  #print(loss2) \n",
        "  loss = 0.8*loss1 + 0.2*loss2\n",
        "  #print(loss)\n",
        "  return loss #Give 80% importance to classification than sum prediction"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNdSoE4KMcLu"
      },
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  labels = torch.tensor(labels.argmax(dim=1)).long()\n",
        "  #print(preds)\n",
        "  #print(labels)\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMMQ_V_-4f69",
        "outputId": "14000f42-5fd0-47b3-9f5d-1bfb1bbd1ec0"
      },
      "source": [
        "#Train\n",
        "torch.set_grad_enabled(True)\n",
        "train_loader = torch.utils.data.DataLoader(ComData, batch_size=64)\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for batch in train_loader: # Get Batch\n",
        "        images =  batch[0]\n",
        "        #print(images.shape)\n",
        "\n",
        "        datas = batch[1]\n",
        "        #print(datas.shape)\n",
        "\n",
        "        labels1 = batch[2]\n",
        "        #print(\"Label 1 shape= \",labels1.shape)\n",
        "\n",
        "        labels2 = batch[3]\n",
        "        #print(\"Label 2 shape= \",labels2.shape)\n",
        "\n",
        "        out1, out2 = network(images,datas) # Pass Batch\n",
        "        #print(\"Out1 shape=\",out1.shape)\n",
        "        #print(\"Out2 shape =\",out2.shape)\n",
        "        loss = combined_loss_function(out1, labels1, out2, labels2) # Calculate combined Loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() # Calculate Gradients\n",
        "        optimizer.step() # Update Weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += get_num_correct(out1, labels1)\n",
        "        \n",
        "\n",
        "    print(\n",
        "        \"epoch\", epoch, \n",
        "        \"total_correct:\", total_correct, \n",
        "        \"loss:\", total_loss\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        }
      ]
    }
  ]
}