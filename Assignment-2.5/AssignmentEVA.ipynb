{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AssignmentEVA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILUxchR5qGar",
        "outputId": "77d57463-e4fd-488e-9f52-8d53e822c49c"
      },
      "source": [
        "#Do all Installations\n",
        "!pip install torch\n",
        "!pip install torchsummary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YT6LGBSpXF7"
      },
      "source": [
        "#Do all Imports\n",
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgdeIxgYqElW"
      },
      "source": [
        "#Do all Downloads\n",
        "mnist = datasets.MNIST(root = \"./data\", train = True, download = True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogudg9scpbZ8",
        "outputId": "029c3bcf-12e2-46d8-ba85-1d0e5907d91d"
      },
      "source": [
        "#Create combined dataset\n",
        "import torch.nn.functional as F\n",
        "Combined_Dataset = []\n",
        "for sample_data in iter(mnist):\n",
        "  sample_image, sample_label = sample_data\n",
        "  first_input = sample_image\n",
        "  first_label = sample_label\n",
        "  for i in range(10):\n",
        "    second_label = first_label + i\n",
        "    second_input = i\n",
        "    first_label = torch.tensor(first_label)\n",
        "    second_label_onehot = torch.tensor(second_label)\n",
        "    second_label_onehot = F.one_hot(second_label_onehot, num_classes=19).float()\n",
        "    second_input_onehot = torch.tensor(second_input)\n",
        "    second_input_onehot = F.one_hot(second_input_onehot, num_classes=10)\n",
        "    first_label_onehot = F.one_hot(first_label, num_classes=10)\n",
        "    combined_sample = (first_input,second_input_onehot,first_label_onehot,second_label_onehot)\n",
        "    Combined_Dataset.append(combined_sample)\n",
        "\n",
        "print(\"Dataset size = \",len(Combined_Dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size =  600000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNZ1_eV8ty6s",
        "outputId": "259851b7-c93b-44e9-c32a-41b512578c48"
      },
      "source": [
        "Combined_Dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860, -0.1951,\n",
              "           -0.1951, -0.1951,  1.1795,  1.3068,  1.8032, -0.0933,  1.6887,\n",
              "            2.8215,  2.7197,  1.1923, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.0424,  0.0340,  0.7722,  1.5359,  1.7396,  2.7960,\n",
              "            2.7960,  2.7960,  2.7960,  2.7960,  2.4396,  1.7650,  2.7960,\n",
              "            2.6560,  2.0578,  0.3904, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "            0.1995,  2.6051,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
              "            2.7960,  2.7960,  2.7960,  2.7706,  0.7595,  0.6195,  0.6195,\n",
              "            0.2886,  0.0722, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.1951,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
              "            2.0960,  1.8923,  2.7197,  2.6433, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242,  0.5940,  1.5614,  0.9377,  2.7960,  2.7960,  2.1851,\n",
              "           -0.2842, -0.4242,  0.1231,  1.5359, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.2460, -0.4115,  1.5359,  2.7960,  0.7213,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242,  1.3450,  2.7960,  1.9942,\n",
              "           -0.3988, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.2842,  1.9942,  2.7960,\n",
              "            0.4668, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0213,  2.6433,\n",
              "            2.4396,  1.6123,  0.9504, -0.4115, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6068,\n",
              "            2.6306,  2.7960,  2.7960,  1.0904, -0.1060, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "            0.1486,  1.9432,  2.7960,  2.7960,  1.4850, -0.0806, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.2206,  0.7595,  2.7833,  2.7960,  1.9560, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242,  2.7451,  2.7960,  2.7451,  0.3904,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "            0.1613,  1.2305,  1.9051,  2.7960,  2.7960,  2.2105, -0.3988,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0722,  1.4596,\n",
              "            2.4906,  2.7960,  2.7960,  2.7960,  2.7578,  1.8923, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.1187,  1.0268,  2.3887,  2.7960,\n",
              "            2.7960,  2.7960,  2.7960,  2.1342,  0.5686, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.1315,  0.4159,  2.2869,  2.7960,  2.7960,  2.7960,\n",
              "            2.7960,  2.0960,  0.6068, -0.3988, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1951,\n",
              "            1.7523,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.0578,\n",
              "            0.5940, -0.3097, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242,  0.2758,  1.7650,  2.4524,\n",
              "            2.7960,  2.7960,  2.7960,  2.7960,  2.6815,  1.2686, -0.2842,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242,  1.3068,  2.7960,  2.7960,\n",
              "            2.7960,  2.2742,  1.2941,  1.2559, -0.2206, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
              "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
              "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]]),\n",
              " tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24V7CeIZq6QN"
      },
      "source": [
        "#Trainset = Combined_Dataset[0:0.8*len(Combined_Dataset)]\n",
        "#Testset = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCtL1eiRquFE"
      },
      "source": [
        "#Create class and iterator\n",
        "class MnistNumberCombinedDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = Combined_Dataset\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "ComData = MnistNumberCombinedDataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgwgSsBDr2TJ"
      },
      "source": [
        "#Create Network class\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # input size = 28 | output size = 24 | numb_channels = 10\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5) \n",
        "    \n",
        "    # input size = 24 | output size = 12 | numb_channels = 10\n",
        "    self.maxpool1 = nn.MaxPool2d(2,2)\n",
        "    \n",
        "    # input size = 12 | output size = 8 | numb_channels = 16\n",
        "    self.conv2 = nn.Conv2d(in_channels=10, out_channels=16, kernel_size=3)\n",
        "\n",
        "    self.conv2drop = nn.Dropout2d()\n",
        "\n",
        "    # input size = 8 | output size = 4 | numb_channels = 16\n",
        "    self.maxpool2 = nn.MaxPool2d(2,2)\n",
        "\n",
        "    \n",
        "    self.fc1 = nn.Linear(in_features = 400,out_features = 50)\n",
        "\n",
        "    self.out1  = nn.Linear(in_features = 50,out_features = 10)\n",
        "\n",
        "    # input size = 10 + 10 | output size = 50\n",
        "    self.fc2 = nn.Linear(in_features=20, out_features=50)\n",
        "\n",
        "    # input size = 50 | output size = 70\n",
        "    self.fc3 = nn.Linear(in_features=50, out_features=70)\n",
        "\n",
        "    # input size = 70 | output size = 19\n",
        "    self.out2 = nn.Linear(in_features=70, out_features=19)\n",
        "    \n",
        "\n",
        "  \n",
        "  def forward(self, image, data):\n",
        "    #print(\"Input Image size = \", image.shape)\n",
        "    x = F.relu(self.maxpool1(self.conv1(image)))\n",
        "    #print(\"After 1st conv size and maxpool1 = \", x.shape)\n",
        "\n",
        "    x = F.relu(self.maxpool2(self.conv2drop(self.conv2(x))))\n",
        "    #print(\"After 2nd conv and Maxpool2 size = \", x.shape)\n",
        "\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    #print(type(x))\n",
        "    #print(\"After reshape size = \",x.shape)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    #print(\"After fc1 size = \",x.shape)\n",
        "\n",
        "    x = F.relu(self.out1(x))\n",
        "    #print(\"After second fc(out1), out =\", x.shape)\n",
        "\n",
        "    self.out1_pred = F.log_softmax(x)\n",
        "\n",
        "    #print(\"Input data size = \", data.shape)\n",
        "    concat = torch.cat((self.out1_pred, data),dim=1)\n",
        "    #print(\"After Concat size = \", concat.shape)\n",
        "\n",
        "    concat = concat.reshape(concat.shape[0],-1)\n",
        "    #print(\"After reshape concat size = \",concat.shape)\n",
        "\n",
        "    x = F.relu(self.fc2(concat))\n",
        "    #print(\"After 2nd FC  size = \", x.shape)\n",
        "    \n",
        "    x = F.relu(self.fc3(x))\n",
        "    #print(\"After 3rd FC  size = \", x.shape)\n",
        "    \n",
        "    self.out_pred2 = F.relu(self.out2(x))\n",
        "    #print(\"After out2 FC, 2nd Output size = \", self.out_pred2.shape)\n",
        "\n",
        "    return (self.out1_pred, self.out_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FPIdMIK1qe0",
        "outputId": "befe7f93-2cf3-43f6-94bf-90ffff44bb4c"
      },
      "source": [
        "#initialize Network object\n",
        "network = Network()\n",
        "\n",
        "for name, param in network.named_parameters():\n",
        "  print(name, '\\t\\t', param.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight \t\t torch.Size([10, 1, 5, 5])\n",
            "conv1.bias \t\t torch.Size([10])\n",
            "conv2.weight \t\t torch.Size([16, 10, 3, 3])\n",
            "conv2.bias \t\t torch.Size([16])\n",
            "fc1.weight \t\t torch.Size([50, 400])\n",
            "fc1.bias \t\t torch.Size([50])\n",
            "out1.weight \t\t torch.Size([10, 50])\n",
            "out1.bias \t\t torch.Size([10])\n",
            "fc2.weight \t\t torch.Size([50, 20])\n",
            "fc2.bias \t\t torch.Size([50])\n",
            "fc3.weight \t\t torch.Size([70, 50])\n",
            "fc3.bias \t\t torch.Size([70])\n",
            "out2.weight \t\t torch.Size([19, 70])\n",
            "out2.bias \t\t torch.Size([19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoBPpp4h4Ida"
      },
      "source": [
        "def combined_loss_function(out1, labels1, out2, labels2):\n",
        "  #out1_argmax = torch.tensor(out1.argmax(dim = 1)).float()\n",
        "  #print(out1_argmax)\n",
        "  #print(out1_argmax.shape)\n",
        "  labels1_argmax = torch.tensor(labels1.argmax(dim=1)).long()\n",
        "  crossentropyloss = nn.CrossEntropyLoss()\n",
        "  loss1 = crossentropyloss(out1, labels1_argmax) #Cross entropy for image\n",
        "  mse_loss = nn.MSELoss() #MSE for sum prediction\n",
        "  loss2 = mse_loss(out2, labels2)\n",
        "  #print(loss1)\n",
        "  #print(loss2) \n",
        "  loss = 0.8*loss1 + 0.2*loss2\n",
        "  #print(loss)\n",
        "  return loss #Give 80% importance to classification than sum prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNdSoE4KMcLu"
      },
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  labels = torch.tensor(labels.argmax(dim=1)).long()\n",
        "  #print(preds)\n",
        "  #print(labels)\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MMMQ_V_-4f69",
        "outputId": "c2577bb8-638f-4e39-c43a-d2d15869038c"
      },
      "source": [
        "#Train\n",
        "torch.set_grad_enabled(True)\n",
        "train_loader = torch.utils.data.DataLoader(ComData, batch_size=64)\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for batch in train_loader: # Get Batch\n",
        "        images =  batch[0]\n",
        "        #print(images.shape)\n",
        "\n",
        "        datas = batch[1]\n",
        "        #print(datas.shape)\n",
        "\n",
        "        labels1 = batch[2]\n",
        "        #print(\"Label 1 shape= \",labels1.shape)\n",
        "\n",
        "        labels2 = batch[3]\n",
        "        #print(\"Label 2 shape= \",labels2.shape)\n",
        "\n",
        "        out1, out2 = network(images,datas) # Pass Batch\n",
        "        #print(\"Out1 shape=\",out1.shape)\n",
        "        #print(\"Out2 shape =\",out2.shape)\n",
        "        loss = combined_loss_function(out1, labels1, out2, labels2) # Calculate combined Loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() # Calculate Gradients\n",
        "        optimizer.step() # Update Weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += get_num_correct(out1, labels1)\n",
        "        \n",
        "\n",
        "    print(\n",
        "        \"epoch\", epoch, \n",
        "        \"total_correct:\", total_correct, \n",
        "        \"loss:\", total_loss\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0520, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0519, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0526, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8526, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0520, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0519, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0519, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0526, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8526, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0517, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0517, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0519, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0503, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8521, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0519, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0523, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0517, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0520, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0521, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0503, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8521, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0517, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0517, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0523, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8521, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0524, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0522, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8521, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0502, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8521, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0517, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0505, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0520, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0502, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8521, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0525, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8526, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0517, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0503, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8521, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0504, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8521, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0521, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0515, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0514, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0509, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0520, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8525, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0510, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0512, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0507, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8524, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8523, grad_fn=<AddBackward0>)\n",
            "tensor(2.3026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8522, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-232-cc232fb6fede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(\"Label 2 shape= \",labels2.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass Batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(\"Out1 shape=\",out1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(\"Out2 shape =\",out2.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-226-12379a5b4c20>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, data)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#print(\"Input Image size = \", image.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;31m#print(\"After 1st conv size and maxpool1 = \", x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}